@Article{csaw2016,
    author = {Aaron T L Lun and Gordon K Smyth},
    title = {csaw: a {B}ioconductor package for differential binding analysis of {C}h{I}{P}-seq data using sliding windows},
    journal = {Nucleic Acids Res.},
    year = {2016},
    volume = {44},
    number = {5},
    pages = {e45},
  }


@ARTICLE{Zhang2008-ms,
  title    = "Model-based analysis of {ChIP-Seq} ({MACS})",
  author   = "Zhang, Yong and Liu, Tao and Meyer, Clifford A and Eeckhoute,
              J{\'e}r{\^o}me and Johnson, David S and Bernstein, Bradley E and
              Nusbaum, Chad and Myers, Richard M and Brown, Myles and Li, Wei
              and Liu, X Shirley",
  abstract = "We present Model-based Analysis of ChIP-Seq data, MACS, which
              analyzes data generated by short read sequencers such as Solexa's
              Genome Analyzer. MACS empirically models the shift size of
              ChIP-Seq tags, and uses it to improve the spatial resolution of
              predicted binding sites. MACS also uses a dynamic Poisson
              distribution to effectively capture local biases in the genome,
              allowing for more robust predictions. MACS compares favorably to
              existing ChIP-Seq peak-finding algorithms, and is freely
              available.",
  journal  = "Genome Biol.",
  volume   =  9,
  number   =  9,
  pages    = "R137",
  month    =  sep,
  year     =  2008,
  language = "en"
}


@ARTICLE{Gandolfo2018-oc,
  title    = "{RLE} plots: Visualizing unwanted variation in high dimensional
              data",
  author   = "Gandolfo, Luke C and Speed, Terence P",
  abstract = "Unwanted variation can be highly problematic and so its detection
              is often crucial. Relative log expression (RLE) plots are a
              powerful tool for visualizing such variation in high dimensional
              data. We provide a detailed examination of these plots, with the
              aid of examples and simulation, explaining what they are and what
              they can reveal. RLE plots are particularly useful for assessing
              whether a procedure aimed at removing unwanted variation, i.e. a
              normalization procedure, has been successful. These plots, while
              originally devised for gene expression data from microarrays, can
              also be used to reveal unwanted variation in many other kinds of
              high dimensional data, where such variation can be problematic.",
  journal  = "PLoS One",
  volume   =  13,
  number   =  2,
  pages    = "e0191629",
  month    =  feb,
  year     =  2018,
  language = "en"
}


@ARTICLE{Lund2012-xo,
  title    = "Detecting differential expression in {RNA-sequence} data using
              quasi-likelihood with shrunken dispersion estimates",
  author   = "Lund, Steven P and Nettleton, Dan and McCarthy, Davis J and
              Smyth, Gordon K",
  abstract = "Next generation sequencing technology provides a powerful tool
              for measuring gene expression (mRNA) levels in the form of
              RNA-sequence data. Method development for identifying
              differentially expressed (DE) genes from RNA-seq data, which
              frequently includes many low-count integers and can exhibit
              severe overdispersion relative to Poisson or binomial
              distributions, is a popular area of ongoing research. Here we
              present quasi-likelihood methods with shrunken dispersion
              estimates based on an adaptation of Smyth's (2004) approach to
              estimating gene-specific error variances for microarray data. Our
              suggested methods are computationally simple, analogous to ANOVA
              and compare favorably versus competing methods in detecting DE
              genes and estimating false discovery rates across a variety of
              simulations based on real data.",
  journal  = "Stat. Appl. Genet. Mol. Biol.",
  volume   =  11,
  number   =  5,
  month    =  oct,
  year     =  2012,
  language = "en"
}


@ARTICLE{Law2014-xq,
  title    = "voom: Precision weights unlock linear model analysis tools for
              {RNA-seq} read counts",
  author   = "Law, Charity W and Chen, Yunshun and Shi, Wei and Smyth, Gordon K",
  abstract = "New normal linear modeling strategies are presented for analyzing
              read counts from RNA-seq experiments. The voom method estimates
              the mean-variance relationship of the log-counts, generates a
              precision weight for each observation and enters these into the
              limma empirical Bayes analysis pipeline. This opens access for
              RNA-seq analysts to a large body of methodology developed for
              microarrays. Simulation studies show that voom performs as well
              or better than count-based RNA-seq methods even when the data are
              generated according to the assumptions of the earlier methods.
              Two case studies illustrate the use of linear modeling and gene
              set testing methods.",
  journal  = "Genome Biol.",
  volume   =  15,
  number   =  2,
  pages    = "R29",
  month    =  feb,
  year     =  2014,
  language = "en"
}

@Article{DiffBind2012,
    title = {Differential oestrogen receptor binding is associated with clinical outcome in breast cancer},
    author = {Caryn S. Ross-Innes and Rory Stark and Andrew E. Teschendorff and Kelly A. Holmes and H. Raza Ali and Mark J. Dunning and Gordon D. Brown and Ondrej Gojis and Ian O. Ellis and Andrew R. Green and Simak Ali and Suet-Feung Chin and Carlo Palmieri and Carlos Caldas and Jason S. Carroll},
    journal = {Nature},
    year = {2012},
    volume = {481},
    pages = {-4},
    url = {http://www.nature.com/nature/journal/v481/n7381/full/nature10730.html},
  }


@ARTICLE{McCarthy2009-qf,
  title    = "Testing significance relative to a fold-change threshold is a
              {TREAT}",
  author   = "McCarthy, Davis J and Smyth, Gordon K",
  abstract = "MOTIVATION: Statistical methods are used to test for the
              differential expression of genes in microarray experiments. The
              most widely used methods successfully test whether the true
              differential expression is different from zero, but give no
              assurance that the differences found are large enough to be
              biologically meaningful. RESULTS: We present a method, t-tests
              relative to a threshold (TREAT), that allows researchers to test
              formally the hypothesis (with associated p-values) that the
              differential expression in a microarray experiment is greater
              than a given (biologically meaningful) threshold. We have
              evaluated the method using simulated data, a dataset from a
              quality control experiment for microarrays and data from a
              biological experiment investigating histone deacetylase
              inhibitors. When the magnitude of differential expression is
              taken into account, TREAT improves upon the false discovery rate
              of existing methods and identifies more biologically relevant
              genes. AVAILABILITY: R code implementing our methods is
              contributed to the software package limma available at
              http://www.bioconductor.org.",
  journal  = "Bioinformatics",
  volume   =  25,
  number   =  6,
  pages    = "765--771",
  month    =  mar,
  year     =  2009,
  language = "en"
}


@ARTICLE{Wilson2019-ln,
  title    = "The harmonic mean \textit{p}-value for combining dependent tests",
  author   = "Wilson, Daniel J",
  abstract = "Analysis of ``big data'' frequently involves statistical
              comparison of millions of competing hypotheses to discover hidden
              processes underlying observed patterns of data, for example, in
              the search for genetic determinants of disease in genome-wide
              association studies (GWAS). Controlling the familywise error rate
              (FWER) is considered the strongest protection against false
              positives but makes it difficult to reach the multiple
              testing-corrected significance threshold. Here, I introduce the
              harmonic mean p-value (HMP), which controls the FWER while
              greatly improving statistical power by combining dependent tests
              using generalized central limit theorem. I show that the HMP
              effortlessly combines information to detect statistically
              significant signals among groups of individually nonsignificant
              hypotheses in examples of a human GWAS for neuroticism and a
              joint human-pathogen GWAS for hepatitis C viral load. The HMP
              simultaneously tests all ways to group hypotheses, allowing the
              smallest groups of hypotheses that retain significance to be
              sought. The power of the HMP to detect significant hypothesis
              groups is greater than the power of the Benjamini-Hochberg
              procedure to detect significant hypotheses, although the latter
              only controls the weaker false discovery rate (FDR). The HMP has
              broad implications for the analysis of large datasets, because it
              enhances the potential for scientific discovery.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  116,
  number   =  4,
  pages    = "1195--1200",
  month    =  jan,
  year     =  2019,
  keywords = "big data; false positives; model averaging; multiple testing;
              p-values",
  language = "en"
}

@Article{edgeR2016,
    author = {Yunshun Chen and Aaron A T Lun and Gordon K Smyth},
    title = {From reads to genes to pathways: differential expression analysis of RNA-Seq experiments using Rsubread and the edgeR quasi-likelihood pipeline},
    year = {2016},
    journal = {F1000Research},
    volume = {5},
    pages = {1438},
    doi = {10.12688/f1000research.8987.2},
  }

@Article{DESeq22014,
    title = {Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2},
    author = {Michael I. Love and Wolfgang Huber and Simon Anders},
    year = {2014},
    journal = {Genome Biology},
    doi = {10.1186/s13059-014-0550-8},
    volume = {15},
    issue = {12},
    pages = {550},
  }


@ARTICLE{Molder2021-mo,
  title    = "Sustainable data analysis with Snakemake",
  author   = "M{\"o}lder, Felix and Jablonski, Kim Philipp and Letcher, Brice
              and Hall, Michael B and Tomkins-Tinch, Christopher H and Sochat,
              Vanessa and Forster, Jan and Lee, Soohyun and Twardziok, Sven O
              and Kanitz, Alexander and Wilm, Andreas and Holtgrewe, Manuel and
              Rahmann, Sven and Nahnsen, Sven and K{\"o}ster, Johannes",
  abstract = "Data analysis often entails a multitude of heterogeneous steps,
              from the application of various command line tools to the usage
              of scripting languages like R or Python for the generation of
              plots and tables. It is widely recognized that data analyses
              should ideally be conducted in a reproducible way.
              Reproducibility enables technical validation and regeneration of
              results on the original or even new data. However,
              reproducibility alone is by no means sufficient to deliver an
              analysis that is of lasting impact (i.e., sustainable) for the
              field, or even just one research group. We postulate that it is
              equally important to ensure adaptability and transparency. The
              former describes the ability to modify the analysis to answer
              extended or slightly different research questions. The latter
              describes the ability to understand the analysis in order to
              judge whether it is not only technically, but methodologically
              valid. Here, we analyze the properties needed for a data analysis
              to become reproducible, adaptable, and transparent. We show how
              the popular workflow management system Snakemake can be used to
              guarantee this, and how it enables an ergonomic, combined,
              unified representation of all steps involved in data analysis,
              ranging from raw data processing, to quality control and
              fine-grained, interactive exploration and plotting of final
              results.",
  journal  = "F1000Res.",
  volume   =  10,
  pages    = "33",
  month    =  jan,
  year     =  2021,
  keywords = "adaptability; data analysis; reproducibility; scalability;
              sustainability; transparency; workflow management",
  language = "en"
}


@ARTICLE{Hicks2015-ee,
  title    = "quantro: a data-driven approach to guide the choice of an
              appropriate normalization method",
  author   = "Hicks, Stephanie C and Irizarry, Rafael A",
  abstract = "Normalization is an essential step in the analysis of
              high-throughput data. Multi-sample global normalization methods,
              such as quantile normalization, have been successfully used to
              remove technical variation. However, these methods rely on the
              assumption that observed global changes across samples are due to
              unwanted technical variability. Applying global normalization
              methods has the potential to remove biologically driven
              variation. Currently, it is up to the subject matter experts to
              determine if the stated assumptions are appropriate. Here, we
              propose a data-driven alternative. We demonstrate the utility of
              our method (quantro) through examples and simulations. A software
              implementation is available from
              http://www.bioconductor.org/packages/release/bioc/html/quantro.html
              .",
  journal  = "Genome Biol.",
  volume   =  16,
  number   =  1,
  pages    = "117",
  month    =  jun,
  year     =  2015,
  language = "en"
}


@ARTICLE{Robinson2010-qp,
  title    = "A scaling normalization method for differential expression
              analysis of {RNA-seq} data",
  author   = "Robinson, Mark D and Oshlack, Alicia",
  abstract = "The fine detail provided by sequencing-based transcriptome
              surveys suggests that RNA-seq is likely to become the platform of
              choice for interrogating steady state RNA. In order to discover
              biologically important changes in expression, we show that
              normalization continues to be an essential step in the analysis.
              We outline a simple and effective method for performing
              normalization and show dramatically improved results for
              inferring differential expression in simulated and publicly
              available data sets.",
  journal  = "Genome Biol.",
  volume   =  11,
  number   =  3,
  pages    = "R25",
  month    =  mar,
  year     =  2010,
  language = "en"
}


@ARTICLE{Hansen2012-jz,
  title     = "Removing technical variability in {RNA-seq} data using
               conditional quantile normalization",
  author    = "Hansen, Kasper D and Irizarry, Rafael A and Wu, Zhijin",
  abstract  = "The ability to measure gene expression on a genome-wide scale is
               one of the most promising accomplishments in molecular biology.
               Microarrays, the technology that first permitted this, were
               riddled with problems due to unwanted sources of variability.
               Many of these problems are now mitigated, after a decade's worth
               of statistical methodology development. The recently developed
               RNA sequencing (RNA-seq) technology has generated much
               excitement in part due to claims of reduced variability in
               comparison to microarrays. However, we show that RNA-seq data
               demonstrate unwanted and obscuring variability similar to what
               was first observed in microarrays. In particular, we find
               guanine-cytosine content (GC-content) has a strong
               sample-specific effect on gene expression measurements that, if
               left uncorrected, leads to false positives in downstream
               results. We also report on commonly observed data distortions
               that demonstrate the need for data normalization. Here, we
               describe a statistical methodology that improves precision by
               42\% without loss of accuracy. Our resulting conditional
               quantile normalization algorithm combines robust generalized
               regression to remove systematic bias introduced by deterministic
               features such as GC-content and quantile normalization to
               correct for global distortions.",
  journal   = "Biostatistics",
  publisher = "academic.oup.com",
  volume    =  13,
  number    =  2,
  pages     = "204--216",
  month     =  apr,
  year      =  2012,
  language  = "en"
}

@InBook{gviz,
    author = {Florian Hahne and Robert Ivanek},
    editor = {Ewy Math{\'e} and Sean Davis},
    chapter = {Visualizing Genomic Data Using Gviz and Bioconductor},
    title = {Statistical Genomics: Methods and Protocols},
    year = {2016},
    publisher = {Springer New York},
    address = {New York, NY},
    pages = {335--351},
    isbn = {978-1-4939-3578-9},
    doi = {10.1007/978-1-4939-3578-9_16},
    url = {http://dx.doi.org/10.1007/978-1-4939-3578-9_16},
  }
